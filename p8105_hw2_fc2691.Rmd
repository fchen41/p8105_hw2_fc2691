---
title: "p8105_hw2_fc2691"
author: "FC"
date: "10/3/2021"
output: html_document
---

## Problem 1  

This problem uses the Mr. Trash Wheel dataset, available as an Excel file on the course website.  

Read and clean the Mr. Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
- use reasonable variable names
- omit rows that do not include dumpster-specific data
- round the number of sports balls to the nearest integer  

Read and clean precipitation data for 2018 and 2019. For each, omit rows without precipitation data and add a variable for year. Next, combine precipitation datasets and convert month to a character variable (the variable month.name is built into R and should be useful).

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2018? What was the median number of sports balls in a dumpster in 2019?

```{r}
library(readxl)
library(tidyverse)
library(dplyr)
library(tidyr)

# #Clean the data in Mr. Trash Wheel Sheet. 
mr_trash_wheel_sheet =
  readxl::read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", range = "A2:N534") %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>% 
  mutate(sports_balls = round(sports_balls,0))

mr_trash_wheel_sheet

#clean precipitation data for 2018 and 2019

#Reorganize precipitation data for 2018
precipitation_data_2018 = 
  readxl::read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", sheet = "2018 Precipitation", range = "A2:B15") %>% 
  janitor::clean_names() %>%
  drop_na() %>% 
  mutate(year = 2018)

##Reorganize precipitation data for 2019
precipitation_data_2019 = 
  readxl::read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", sheet = "2019 Precipitation", range = "A2:B15") %>% 
  janitor::clean_names() %>%
  drop_na() %>% 
  mutate(year = 2019)

precipitation_data_clean = 
  full_join(
    precipitation_data_2018, precipitation_data_2019
  ) %>% 
  mutate(month = month.name[month]) %>% 
  relocate(year, month, total)

precipitation_data_clean

```

In Mr.Trash Wheel sheet, there are data from 2014 to 2021 with 14 variables and 453 observations. In the joint precipitation data for 2018 and 2019, there are 24 observations and 3 variables  Among those data, it could be concluded that the total precipitation in 2018 is `r with(precipitation_data_clean, sum(total[year == 2018]))`. The median number of sports balls in dumpster in 2019 is `r with(mr_trash_wheel_sheet, median(sports_balls[year == 2019]))`.

## Problem 2  

This problem uses the *FiveThirtyEight* data; these data were gathered to create the interactive graphic on this page. In particular, 



```{r}
#Clean the data in pols-month.csv

library(tidyr)
pols_month_number = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(
    col = mon, into = c("year", "month", "day"), sep = "-"
    ) %>% 
  mutate(month = month.abb[as.numeric(month)]) %>%
  mutate(president = ifelse(prez_gop == 1, "gop", "dem")) %>% 
  select(-prez_gop, -prez_dem, -day)

pols_month_number


#Clean the data in snp.csv


snp_stock =
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>% 
  mutate(date = as.Date(date, "%m/%d/%y")) %>% 
  separate(
    col = date, into = c("year", "month", "day"), sep = "-"
    ) %>%
  mutate(month = month.abb[as.numeric(month)]) %>%
  arrange(year, month) %>%
  relocate(year, month, everything()) %>%
  select(-day)
snp_stock

# Tidy the unemployment data so that it can be merged with the previous datasets.

unemployment_percentage =
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec, 
    names_to = "month", 
    values_to = "month_data"
  ) %>% 
  mutate(year = as.character(year))

unemployment_percentage

#Join the datasets by merging snp into pols, and merging unemployment into the result.

pols_snp_unemployment_merge = full_join(full_join(pols_month_number, snp_stock), unemployment_percentage)

pols_snp_unemployment_merge
```

## Problem 3  

Load and tidy the data.   
Produce a well-structured, reader-friendly table showing the rank in popularity of the name “Olivia” as a female baby name over time; this should have rows for ethnicities and columns for year. Produce a similar table showing the most popular name among male children over time.

Finally, for male, white non-hispanic children born in 2016, produce a scatter plot showing the number of children with a name (y axis) against the rank in popularity of that name (x axis).
```{r}
# Load the data and remove the duplicates. 

popular_baby_names =
  read_csv("./data/Popular_Baby_Names.csv") %>%
  janitor::clean_names() %>% 
  distinct() %>% 
  #Showing the rank in popularity of the name “Olivia” as a female baby name over time
  filter(gender == "FEMALE" & childs_first_name == "Olivia") %>%
  select(-gender) %>%
  pivot_wider(
    names_from = c(ethnicity),
    values_from = c(year_of_birth)
    )
popular_baby_names

popular_male_baby_names_count =
  read_csv("./data/Popular_Baby_Names.csv") %>%
  janitor::clean_names() %>% 
  mutate(
    gender = str_to_title(gender), 
    ethnicity = str_to_title(ethnicity), 
    childs_first_name = str_to_title(childs_first_name)
    ) %>% 
  distinct() %>% 
  filter(gender == "Female") %>% 
  group_by(childs_first_name) %>%
  summarise(
    total_count = sum(count), 
    rank_avg = mean(rank)
    ) %>% 
  arrange(desc(total_count))

popular_male_baby_names_count
```



